name: Test Chess Engines

on:
  pull_request:
    branches: [ master ]
  workflow_dispatch:
    inputs:
      test_all:
        description: 'Test all implementations (ignore changes)'
        required: false
        default: false
        type: boolean

env:
  DOCKER_BUILDKIT: 1

jobs:
  detect-changes:
    name: Detect Changed Implementations
    runs-on: ubuntu-latest
    outputs:
      changed-implementations: ${{ steps.changes.outputs.implementations }}
      has-changes: ${{ steps.changes.outputs.has-changes }}
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect changed implementations
        id: changes
        run: |
          # Determine if we should test all implementations
          if [[ "${{ github.event_name }}" == "workflow_dispatch" && "${{ github.event.inputs.test_all }}" == "true" ]]; then
            echo "🔄 Manual trigger: Testing all implementations"
            CHANGED_IMPLEMENTATIONS="all"
            HAS_CHANGES="true"
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "🔍 Pull Request: Detecting changes"
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} -- implementations/ || echo "")
            
            if [[ -n "$CHANGED_FILES" ]]; then
              CHANGED_IMPLEMENTATIONS=$(echo "$CHANGED_FILES" | grep -E "^implementations/[^/]+/" | cut -d'/' -f2 | sort -u | tr '\n' ' ')
              HAS_CHANGES="true"
            else
              CHANGED_IMPLEMENTATIONS=""
              HAS_CHANGES="false"
            fi
          else
            # For manual workflow_dispatch without test_all
            echo "🔄 Manual trigger: Detecting recent changes"
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD -- implementations/ || echo "")
            
            if [[ -n "$CHANGED_FILES" ]]; then
              CHANGED_IMPLEMENTATIONS=$(echo "$CHANGED_FILES" | grep -E "^implementations/[^/]+/" | cut -d'/' -f2 | sort -u | tr '\n' ' ')
              HAS_CHANGES="true"
            else
              CHANGED_IMPLEMENTATIONS=""
              HAS_CHANGES="false"
            fi
          fi
          
          echo "Changed implementations: $CHANGED_IMPLEMENTATIONS"
          echo "Has changes: $HAS_CHANGES"
          
          echo "implementations=$CHANGED_IMPLEMENTATIONS" >> $GITHUB_OUTPUT
          echo "has-changes=$HAS_CHANGES" >> $GITHUB_OUTPUT

      - name: Set up Python
        if: steps.changes.outputs.has-changes == 'true'
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Generate dynamic matrix
        id: generate-matrix
        if: steps.changes.outputs.has-changes == 'true'
        run: |
          CHANGED_IMPLEMENTATIONS="${{ steps.changes.outputs.implementations }}"
          
          if [[ "${{ steps.changes.outputs.has-changes }}" == "false" ]]; then
            echo "No implementation changes detected, skipping matrix generation"
            echo 'matrix={"include":[]}' >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Generate matrix using external Python script
          MATRIX_JSON=$(python3 .github/workflows/scripts/generate_matrix.py "$CHANGED_IMPLEMENTATIONS")
          echo "Generated matrix: $MATRIX_JSON"
          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

  validation:
    name: Validate Implementation Structure
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Run structure validation
        run: |
          echo "🔍 Running implementation structure validation..."
          python3 test/verify_implementations.py

  build-test:
    name: Build and Test Chess Engines
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: [detect-changes, validation]
    if: needs.detect-changes.outputs.has-changes == 'true'
    
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Get test configuration
        id: config
        run: |
          echo "🔧 Reading test configuration from chess.meta..."
          CONFIG=$(python3 .github/workflows/scripts/get_test_config.py ${{ matrix.engine }})
          echo "Configuration: $CONFIG"
          
          # Parse configuration
          SUPPORTS_INTERACTIVE=$(echo "$CONFIG" | python3 -c "import sys, json; print(json.load(sys.stdin)['supports_interactive'])")
          SUPPORTS_PERFT=$(echo "$CONFIG" | python3 -c "import sys, json; print(json.load(sys.stdin)['supports_perft'])")
          SUPPORTS_AI=$(echo "$CONFIG" | python3 -c "import sys, json; print(json.load(sys.stdin)['supports_ai'])")
          TEST_MODE=$(echo "$CONFIG" | python3 -c "import sys, json; print(json.load(sys.stdin)['test_mode'])")
          
          echo "supports_interactive=$SUPPORTS_INTERACTIVE" >> $GITHUB_OUTPUT
          echo "supports_perft=$SUPPORTS_PERFT" >> $GITHUB_OUTPUT
          echo "supports_ai=$SUPPORTS_AI" >> $GITHUB_OUTPUT
          echo "test_mode=$TEST_MODE" >> $GITHUB_OUTPUT

      - name: Build Docker image
        run: |
          cd implementations/${{ matrix.engine }}
          echo "🏗️ Building ${{ matrix.engine }} chess engine..."
          docker build -t chess-${{ matrix.engine }}-test .

      - name: Test basic commands
        run: |
          echo "🧪 Testing basic functionality for ${{ matrix.engine }}..."
          
          # Test basic commands that all implementations should support
          echo "📋 Testing help command"
          echo "help" | timeout 30s docker run --rm -i chess-${{ matrix.engine }}-test > help_output.txt || true
          
          echo "📋 Testing board display"
          echo "board" | timeout 30s docker run --rm -i chess-${{ matrix.engine }}-test > board_output.txt || true
          
          echo "📋 Testing FEN export"
          echo "fen" | timeout 30s docker run --rm -i chess-${{ matrix.engine }}-test > fen_output.txt || true
          
          # Basic validation - just check if commands execute without major errors
          if [[ -s help_output.txt ]] && [[ -s board_output.txt ]] && [[ -s fen_output.txt ]]; then
            echo "✅ Basic commands executed successfully"
          else
            echo "⚠️ Some basic commands may have issues"
          fi

      - name: Test advanced features
        if: steps.config.outputs.test_mode == 'full'
        run: |
          echo "🧪 Testing advanced features for ${{ matrix.engine }}..."
          
          # Test perft if supported
          if [[ "${{ steps.config.outputs.supports_perft }}" == "true" ]]; then
            echo "🔍 Testing perft (move generation)"
            echo "perft 3" | timeout 120s docker run --rm -i chess-${{ matrix.engine }}-test > perft_output.txt || true
            
            if grep -E "([0-9]+.*nodes|Depth.*[0-9]+)" perft_output.txt; then
              echo "✅ Perft test completed"
            else
              echo "⚠️ Perft test may have issues"
            fi
          else
            echo "⏭️ Perft not supported, skipping"
          fi
          
          # Test AI if supported
          if [[ "${{ steps.config.outputs.supports_ai }}" == "true" ]]; then
            echo "🤖 Testing AI move generation"
            {
              echo "ai"
              sleep 2
              echo "quit"
            } | timeout 60s docker run --rm -i chess-${{ matrix.engine }}-test > ai_output.txt || true
            
            if [[ -s ai_output.txt ]]; then
              echo "✅ AI test completed"
            else
              echo "⚠️ AI test may have issues"
            fi
          else
            echo "⏭️ AI not supported, skipping"
          fi

      - name: Test demo mode
        if: steps.config.outputs.test_mode == 'demo'
        run: |
          echo "🎯 Running demo mode test for ${{ matrix.engine }}..."
          timeout 30s docker run --rm chess-${{ matrix.engine }}-test || true
          echo "✅ Demo test completed"

      - name: Cleanup
        if: always()
        run: |
          docker rmi chess-${{ matrix.engine }}-test || true
          rm -f *.txt

  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [detect-changes, validation, build-test]
    if: always()
    
    steps:
      - name: Test Results Summary
        run: |
          echo "🏆 Chess Engine Test Summary"
          echo "============================"
          echo ""
          
          CHANGED_IMPLEMENTATIONS="${{ needs.detect-changes.outputs.changed-implementations }}"
          HAS_CHANGES="${{ needs.detect-changes.outputs.has-changes }}"
          
          if [[ "$HAS_CHANGES" == "false" ]]; then
            echo "🚫 No implementation changes detected in this PR"
            echo "⏭️ All tests skipped - no changes to validate"
          elif [[ "$CHANGED_IMPLEMENTATIONS" == "all" ]]; then
            echo "✅ All chess engine implementations tested"
            echo "🔍 Full validation suite completed"
          else
            echo "✅ Changed implementations tested: $CHANGED_IMPLEMENTATIONS"
            echo "🎯 Selective testing completed for modified code only"
          fi
          
          echo ""
          echo "🔧 Convention-based testing features:"
          echo "- 📋 chess.meta file configuration"
          echo "- 🔍 Structure validation via Python script"
          echo "- 🏗️ Docker build verification"
          echo "- 🧪 Adaptive functionality testing"
          echo "- 📊 Dynamic discovery from directory structure"
          echo ""
          echo "✨ Ready for merge when all checks pass!"