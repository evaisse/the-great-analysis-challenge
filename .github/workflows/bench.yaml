name: Benchmark Suite & Release

on:
  push:
    branches: [master]
  schedule:
    # Run every Sunday at 6 AM UTC
    - cron: '0 6 * * 0'
  workflow_dispatch:
    inputs:
      version_type:
        description: 'Version bump type'
        required: true
        default: 'patch'
        type: choice
        options:
          - patch
          - minor
          - major

env:
  PYTHON_VERSION: '3.11'

jobs:
  detect-changes:
    name: Detect Changed Implementations
    runs-on: ubuntu-latest
    outputs:
      changed-implementations: ${{ steps.changes.outputs.implementations }}
      has-changes: ${{ steps.changes.outputs.has-changes }}
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Detect changed implementations
        id: changes
        run: |
          ./workflow detect-changes \
            "${{ github.event_name }}" \
            --test-all "true" \
            --base-sha "${{ github.event.pull_request.base.sha }}" \
            --head-sha "${{ github.sha }}" \
            --before-sha "${{ github.event.before }}"

      - name: Generate matrix for benchmarking
        id: generate-matrix
        if: steps.changes.outputs.has-changes == 'true'
        run: |
          ./workflow generate-matrix \
            "${{ steps.changes.outputs.implementations }}"

  validation:
    name: Validate Structure
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    outputs:
      excellent-count: ${{ steps.verify.outputs.excellent_count }}
      good-count: ${{ steps.verify.outputs.good_count }}
      needs-work-count: ${{ steps.verify.outputs.needs_work_count }}
      total-count: ${{ steps.verify.outputs.total_count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run structure verification
        id: verify
        run: ./workflow verify-implementations

  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    needs: [detect-changes, validation]
    if: needs.detect-changes.outputs.has-changes == 'true'
    timeout-minutes: 20

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install psutil gitpython

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Run benchmark for ${{ matrix.name }}
        run: ./workflow run-benchmark ${{ matrix.engine }} ${{ matrix.directory }} --timeout 300

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-${{ matrix.engine }}-${{ github.sha }}
          path: benchmark_reports/
          retention-days: 30

  combine-results:
    name: Combine Benchmark Results
    runs-on: ubuntu-latest
    needs: [detect-changes, validation, benchmark]
    if: needs.detect-changes.outputs.has-changes == 'true'
    outputs:
      readme-changed: ${{ steps.update.outputs.changed }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Download all benchmark artifacts
        uses: actions/download-artifact@v4
        with:
          path: benchmark_artifacts/

      - name: Combine benchmark results
        run: ./workflow combine-results

      - name: Update README status table
        id: update
        run: ./workflow update-readme

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: [detect-changes, validation, combine-results]
    if: needs.combine-results.outputs.readme-changed == 'true' || github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download benchmark artifacts
        uses: actions/download-artifact@v4
        with:
          path: benchmark_artifacts/

      - name: Determine version and commit changes
        id: version
        run: |
          ./workflow create-release \
            --version-type "${{ github.event.inputs.version_type }}" \
            --readme-changed "${{ needs.combine-results.outputs.readme-changed }}" \
            --excellent-count "${{ needs.validation.outputs.excellent-count }}" \
            --good-count "${{ needs.validation.outputs.good-count }}" \
            --needs-work-count "${{ needs.validation.outputs.needs-work-count }}" \
            --total-count "${{ needs.validation.outputs.total-count }}"

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.version.outputs.new_version }}
          name: 'Chess Engine Implementations ${{ steps.version.outputs.new_version }}'
          body: |
            # Chess Engine Implementation Benchmark Release ${{ steps.version.outputs.new_version }}

            This release contains updated performance benchmarks and status information for chess engine implementations.

            ## 📊 Implementation Status Overview

            - 🟢 **Excellent**: ${{ needs.validation.outputs.excellent-count }} implementations
            - 🟡 **Good**: ${{ needs.validation.outputs.good-count }} implementations  
            - 🔴 **Needs Work**: ${{ needs.validation.outputs.needs-work-count }} implementations

            **Total**: ${{ needs.validation.outputs.total-count }} implementations tested

            ## 🚀 What's Updated

            - ✅ Performance benchmark suite executed using convention-based approach
            - ✅ Implementation structure verification completed
            - ✅ README status table updated with latest results
            - ✅ Matrix-based parallel benchmarking for efficiency

            ---

            *This release was automatically generated by the benchmark suite workflow.*
          draft: false
          prerelease: false

  summary:
    name: Benchmark Summary
    runs-on: ubuntu-latest
    needs: [detect-changes, validation, benchmark, combine-results, release]
    if: always()

    steps:
      - name: Workflow summary
        run: |
          echo "# 🏁 Benchmark Suite Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          HAS_CHANGES="${{ needs.detect-changes.outputs.has-changes }}"
          CHANGED_IMPLEMENTATIONS="${{ needs.detect-changes.outputs.changed-implementations }}"

          if [[ "$HAS_CHANGES" == "false" ]]; then
            echo "🚫 No implementation changes detected - workflow skipped" >> $GITHUB_STEP_SUMMARY
          else
            echo "## 📊 Results" >> $GITHUB_STEP_SUMMARY
            echo "- **Changed implementations**: $CHANGED_IMPLEMENTATIONS" >> $GITHUB_STEP_SUMMARY
            echo "- **Total implementations**: ${{ needs.validation.outputs.total-count }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🟢 **Excellent**: ${{ needs.validation.outputs.excellent-count }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🟡 **Good**: ${{ needs.validation.outputs.good-count }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🔴 **Needs work**: ${{ needs.validation.outputs.needs-work-count }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "✅ Matrix-based benchmarking completed successfully!" >> $GITHUB_STEP_SUMMARY
          fi
