name: Benchmark Suite & Release

on:
  push:
    branches: [ master ]
  schedule:
    # Run every Sunday at 6 AM UTC
    - cron: '0 6 * * 0'
  workflow_dispatch:
    inputs:
      version_type:
        description: 'Version bump type'
        required: true
        default: 'patch'
        type: choice
        options:
          - patch
          - minor
          - major

env:
  PYTHON_VERSION: '3.11'

jobs:
  detect-changes:
    name: Detect Changed Implementations
    runs-on: ubuntu-latest
    outputs:
      changed-implementations: ${{ steps.changes.outputs.implementations }}
      has-changes: ${{ steps.changes.outputs.has-changes }}
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Detect changed implementations
        id: changes
        run: |
          echo "=== Detecting Changed Implementations ==="
          
          # Use reusable change detection script
          RESULT=$(python3 .github/workflows/scripts/detect_changes.py \
            "${{ github.event_name }}" \
            "true" \
            "${{ github.event.pull_request.base.sha }}" \
            "${{ github.sha }}" \
            "${{ github.event.before }}")
          
          echo "Detection result: $RESULT"
          
          IMPLEMENTATIONS=$(echo "$RESULT" | python3 -c "import sys, json; print(json.load(sys.stdin)['implementations'])")
          HAS_CHANGES=$(echo "$RESULT" | python3 -c "import sys, json; print(json.load(sys.stdin)['has_changes'])")
          
          echo "implementations=$IMPLEMENTATIONS" >> $GITHUB_OUTPUT
          echo "has-changes=$HAS_CHANGES" >> $GITHUB_OUTPUT

      - name: Generate matrix for benchmarking
        id: generate-matrix
        if: steps.changes.outputs.has-changes == 'true'
        run: |
          CHANGED_IMPLEMENTATIONS="${{ steps.changes.outputs.implementations }}"
          
          # Generate matrix using existing script
          MATRIX_JSON=$(python3 .github/workflows/scripts/generate_matrix.py "$CHANGED_IMPLEMENTATIONS")
          echo "Generated matrix: $MATRIX_JSON"
          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

  validation:
    name: Validate Structure
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    outputs:
      excellent-count: ${{ steps.verify.outputs.excellent_count }}
      good-count: ${{ steps.verify.outputs.good_count }}
      needs-work-count: ${{ steps.verify.outputs.needs_work_count }}
      total-count: ${{ steps.verify.outputs.total_count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run structure verification
        id: verify
        run: |
          echo "=== Running Implementation Structure Verification ==="
          python3 test/verify_implementations.py > verification_results.txt 2>&1
          
          # Count implementations by status
          EXCELLENT=$(grep -c "🟢.*excellent" verification_results.txt || echo "0")
          GOOD=$(grep -c "🟡.*good" verification_results.txt || echo "0")
          NEEDS_WORK=$(grep -c "🔴.*needs_work" verification_results.txt || echo "0")
          TOTAL=$((EXCELLENT + GOOD + NEEDS_WORK))
          
          echo "excellent_count=$EXCELLENT" >> $GITHUB_OUTPUT
          echo "good_count=$GOOD" >> $GITHUB_OUTPUT
          echo "needs_work_count=$NEEDS_WORK" >> $GITHUB_OUTPUT
          echo "total_count=$TOTAL" >> $GITHUB_OUTPUT
          
          echo "=== Verification Summary ==="
          echo "Total implementations: $TOTAL"
          echo "🟢 Excellent: $EXCELLENT"
          echo "🟡 Good: $GOOD"
          echo "🔴 Needs work: $NEEDS_WORK"

  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    needs: [detect-changes, validation]
    if: needs.detect-changes.outputs.has-changes == 'true'
    timeout-minutes: 90
    
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install psutil gitpython

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Run benchmark for ${{ matrix.name }}
        run: |
          echo "🏁 Running benchmark for ${{ matrix.name }}..."
          
          # Create reports directory
          mkdir -p benchmark_reports
          
          # Run performance test for this specific implementation
          python3 test/performance_test.py \
            --impl "${{ matrix.directory }}" \
            --timeout 900 \
            --output "benchmark_reports/performance_report_${{ matrix.engine }}.txt" \
            --json "benchmark_reports/performance_data_${{ matrix.engine }}.json" \
            > "benchmark_reports/benchmark_output_${{ matrix.engine }}.txt" 2>&1 || true
          
          echo "✅ Benchmark completed for ${{ matrix.name }}"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-${{ matrix.engine }}-${{ github.sha }}
          path: benchmark_reports/
          retention-days: 30

  combine-results:
    name: Combine Benchmark Results
    runs-on: ubuntu-latest
    needs: [detect-changes, validation, benchmark]
    if: needs.detect-changes.outputs.has-changes == 'true'
    outputs:
      readme-changed: ${{ steps.update.outputs.changed }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Download all benchmark artifacts
        uses: actions/download-artifact@v3
        with:
          path: benchmark_artifacts/

      - name: Combine benchmark results
        run: |
          echo "=== Combining Benchmark Results ==="
          
          # Create combined reports directory
          mkdir -p benchmark_reports
          
          # Copy all individual reports
          find benchmark_artifacts/ -name "*.txt" -exec cp {} benchmark_reports/ \;
          find benchmark_artifacts/ -name "*.json" -exec cp {} benchmark_reports/ \;
          
          # Combine JSON reports using existing script
          python3 .github/workflows/scripts/combine_benchmark_results.py
          
          echo "✅ Benchmark results combined"

      - name: Update README status table
        id: update
        run: |
          echo "=== Updating README Status Table ==="
          
          # Update README using existing script
          python3 .github/workflows/scripts/update_readme_status.py
          
          # Check if README was modified
          if git diff --quiet README.md; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "⚠️ README.md was not modified"
          else
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "✅ README.md has been updated"
          fi

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: [detect-changes, validation, combine-results]
    if: needs.combine-results.outputs.readme-changed == 'true' || github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download benchmark artifacts
        uses: actions/download-artifact@v3
        with:
          path: benchmark_artifacts/

      - name: Determine version and commit changes
        id: version
        run: |
          # Get current version
          CURRENT_VERSION=$(git tag --sort=-version:refname | grep -E '^v[0-9]+\.[0-9]+\.[0-9]+$' | head -1 || echo "v0.0.0")
          echo "current_version=$CURRENT_VERSION" >> $GITHUB_OUTPUT
          
          # Determine version bump
          VERSION_TYPE="${{ github.event.inputs.version_type }}"
          if [[ -z "$VERSION_TYPE" ]]; then
            VERSION_TYPE="patch"
          fi
          echo "version_type=$VERSION_TYPE" >> $GITHUB_OUTPUT
          
          # Calculate new version
          IFS='.' read -r -a version_parts <<< "${CURRENT_VERSION#v}"
          MAJOR=${version_parts[0]:-0}
          MINOR=${version_parts[1]:-0}
          PATCH=${version_parts[2]:-0}
          
          case $VERSION_TYPE in
            major) MAJOR=$((MAJOR + 1)); MINOR=0; PATCH=0 ;;
            minor) MINOR=$((MINOR + 1)); PATCH=0 ;;
            patch) PATCH=$((PATCH + 1)) ;;
          esac
          
          NEW_VERSION="v$MAJOR.$MINOR.$PATCH"
          echo "new_version=$NEW_VERSION" >> $GITHUB_OUTPUT
          
          # Configure git and commit changes if README was updated
          if [[ "${{ needs.combine-results.outputs.readme-changed }}" == "true" ]]; then
            git config --local user.email "action@github.com"
            git config --local user.name "GitHub Action"
            
            # Copy benchmark reports to repo
            mkdir -p benchmark_reports
            find benchmark_artifacts/ -name "*.txt" -exec cp {} benchmark_reports/ \;
            find benchmark_artifacts/ -name "*.json" -exec cp {} benchmark_reports/ \;
            
            git add benchmark_reports/ README.md
            
            git commit -m "chore: update implementation status from benchmark suite

Benchmark results summary:
- Total implementations: ${{ needs.validation.outputs.total-count }}
- 🟢 Excellent: ${{ needs.validation.outputs.excellent-count }}
- 🟡 Good: ${{ needs.validation.outputs.good-count }}  
- 🔴 Needs work: ${{ needs.validation.outputs.needs-work-count }}

Performance testing completed with status updates."
            
            git push origin master
            echo "✅ Changes committed and pushed"
          fi
          
          # Create and push tag
          git tag -a "$NEW_VERSION" -m "Release $NEW_VERSION - Benchmark Update"
          git push origin "$NEW_VERSION"
          echo "✅ Release tag $NEW_VERSION created"

      - name: Create GitHub Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ steps.version.outputs.new_version }}
          release_name: "Chess Engine Implementations ${{ steps.version.outputs.new_version }}"
          body: |
            # Chess Engine Implementation Benchmark Release ${{ steps.version.outputs.new_version }}
            
            This release contains updated performance benchmarks and status information for chess engine implementations.
            
            ## 📊 Implementation Status Overview
            
            - 🟢 **Excellent**: ${{ needs.validation.outputs.excellent-count }} implementations
            - 🟡 **Good**: ${{ needs.validation.outputs.good-count }} implementations  
            - 🔴 **Needs Work**: ${{ needs.validation.outputs.needs-work-count }} implementations
            
            **Total**: ${{ needs.validation.outputs.total-count }} implementations tested
            
            ## 🚀 What's Updated
            
            - ✅ Performance benchmark suite executed using convention-based approach
            - ✅ Implementation structure verification completed
            - ✅ README status table updated with latest results
            - ✅ Matrix-based parallel benchmarking for efficiency
            
            ---
            
            *This release was automatically generated by the benchmark suite workflow.*
          draft: false
          prerelease: false

  summary:
    name: Benchmark Summary
    runs-on: ubuntu-latest
    needs: [detect-changes, validation, benchmark, combine-results, release]
    if: always()
    
    steps:
      - name: Workflow summary
        run: |
          echo "# 🏁 Benchmark Suite Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          HAS_CHANGES="${{ needs.detect-changes.outputs.has-changes }}"
          CHANGED_IMPLEMENTATIONS="${{ needs.detect-changes.outputs.changed-implementations }}"
          
          if [[ "$HAS_CHANGES" == "false" ]]; then
            echo "🚫 No implementation changes detected - workflow skipped" >> $GITHUB_STEP_SUMMARY
          else
            echo "## 📊 Results" >> $GITHUB_STEP_SUMMARY
            echo "- **Changed implementations**: $CHANGED_IMPLEMENTATIONS" >> $GITHUB_STEP_SUMMARY
            echo "- **Total implementations**: ${{ needs.validation.outputs.total-count }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🟢 **Excellent**: ${{ needs.validation.outputs.excellent-count }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🟡 **Good**: ${{ needs.validation.outputs.good-count }}" >> $GITHUB_STEP_SUMMARY
            echo "- 🔴 **Needs work**: ${{ needs.validation.outputs.needs-work-count }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "✅ Matrix-based benchmarking completed successfully!" >> $GITHUB_STEP_SUMMARY
          fi